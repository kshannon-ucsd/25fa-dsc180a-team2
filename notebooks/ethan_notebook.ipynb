{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277529a4-5aee-45d9-8a1b-f6a1fcd287d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv('test_final_cohort.csv')\n",
    "\n",
    "# Save as Parquet\n",
    "df.to_parquet('mimic_cohort.parquet')\n",
    "\n",
    "lca_df = pd.read_csv('lca_with_classes.csv')\n",
    "\n",
    "lca_df.to_parquet('lca.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c1ecb-f27d-4efc-ba67-9b9daf9f9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_cohort = pd.read_parquet('mimic_cohort.parquet')\n",
    "mimic_cohort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b1ead-651a-408d-979b-a863065a62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lca_cohort = pd.read_parquet('lca.parquet')\n",
    "lca_cohort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca7880-43ca-4a92-9165-bf2543992247",
   "metadata": {},
   "outputs": [],
   "source": [
    "elixhauser = pd.read_csv(\"elixhauser_ahrq_no_drg_filter.csv\")\n",
    "\n",
    "elixhauser.to_parquet(\"elixhauser.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bdaff-d2ec-4f26-9278-dd4f036e02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "elixhauser_parquet = pd.read_parquet(\"elixhauser.parquet\")\n",
    "elixhauser_parquet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b380e2c3-9435-4be8-b633-05a592ed5f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comorbidity_cols = [\n",
    "    'congestive_heart_failure',\n",
    "    'cardiac_arrhythmias',\n",
    "    'valvular_disease',\n",
    "    'pulmonary_circulation',\n",
    "    'peripheral_vascular',\n",
    "    'hypertension',\n",
    "    'paralysis',\n",
    "    'other_neurological',\n",
    "    'chronic_pulmonary',\n",
    "    'diabetes_uncomplicated',\n",
    "    'diabetes_complicated',\n",
    "    'hypothyroidism',\n",
    "    'renal_failure',\n",
    "    'liver_disease',\n",
    "    'peptic_ulcer',\n",
    "    'aids',\n",
    "    'lymphoma',\n",
    "    'metastatic_cancer',\n",
    "    'solid_tumor',\n",
    "    'rheumatoid_arthritis',\n",
    "    'coagulopathy',\n",
    "    'obesity',\n",
    "    'weight_loss',\n",
    "    'fluid_electrolyte',\n",
    "    'blood_loss_anemia',\n",
    "    'deficiency_anemias',\n",
    "    'alcohol_abuse',\n",
    "    'drug_abuse',\n",
    "    'psychoses',\n",
    "    'depression'\n",
    "]\n",
    "X = elixhauser_parquet[comorbidity_cols].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c454fac-022e-468b-8302-b22d49add6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Age group binning for each patient\n",
    "age_bins = [16, 25, 45, 65, 85, 100]\n",
    "age_labels = ['16-24', '25-44', '45-64', '65-84', '85-100']\n",
    "elixhauser_parquet['age_group'] = pd.cut(elixhauser_parquet['age_years'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "# Prevalence matrix: Index = age_group, Columns = comorbidities\n",
    "prevalence_by_age = elixhauser_parquet.groupby('age_group', observed=False)[comorbidity_cols].mean()\n",
    "# This gives you the table: each cell is prevalence of a comorbidity in that age group\n",
    "n_clusters = 6  # Set to number of clusters used in the paper\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "elixhauser_parquet['cluster'] = cluster_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c2d31-b578-4f4d-8359-314565340455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean presence of each comorbidity feature in each cluster\n",
    "cluster_summary = elixhauser_parquet.groupby('cluster')[comorbidity_cols].mean()\n",
    "print(cluster_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f93acd-8f8b-4b9d-b0c6-65572adf9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Build the graph\n",
    "G = nx.Graph()\n",
    "for comorb in comorbidity_cols:\n",
    "    G.add_node(comorb)\n",
    "\n",
    "# Filter data for the cluster to analyze\n",
    "df_cluster = elixhauser_parquet\n",
    "\n",
    "# Calculate prevalence for nodes (simple fraction having disease)\n",
    "N = len(df_cluster)\n",
    "prevalence = {comorb: df_cluster[comorb].sum() / N for comorb in comorbidity_cols}\n",
    "\n",
    "# --- EDGE CONSTRUCTION WITH RR and 99% CONFIDENCE INTERVAL ---\n",
    "for i, disease_a in enumerate(comorbidity_cols):\n",
    "    for disease_b in comorbidity_cols[i+1:]:\n",
    "        C_AB = ((df_cluster[disease_a]==1) & (df_cluster[disease_b]==1)).sum()\n",
    "        P_A = prevalence[disease_a]\n",
    "        P_B = prevalence[disease_b]\n",
    "        if C_AB > 0 and P_A > 0 and P_B > 0:\n",
    "            RR = (C_AB / N) / (P_A * P_B)\n",
    "            sigma = 1/C_AB + 1/(P_A * P_B * N**2)\n",
    "            lower = RR * np.exp(-1.96 * sigma)\n",
    "            upper = RR * np.exp(1.96 * sigma)\n",
    "            if not (lower <= 1 <= upper):\n",
    "                G.add_edge(disease_a, disease_b, weight=RR)\n",
    "                \n",
    "# Prepare node sizes and caps for better visualization\n",
    "scale_factor = 1.5\n",
    "node_sizes = [prevalence[n] * 2000 for n in G.nodes]  # tune factor for best visual effect\n",
    "\n",
    "# Prepare edge widths and styles\n",
    "edge_weights = [G[u][v]['weight'] for u, v in G.edges]\n",
    "min_weight = min(edge_weights) if edge_weights else 0\n",
    "max_weight = max(edge_weights) if edge_weights else 1  # avoid div zero\n",
    "\n",
    "edge_colors = []\n",
    "edge_widths = []\n",
    "edge_styles = []\n",
    "\n",
    "for u, v in G.edges:\n",
    "    w = G[u][v]['weight']\n",
    "    width = 1 + 4 * (w - min_weight) / (max_weight - min_weight)  # scale width 1-5\n",
    "    edge_widths.append(width)\n",
    "    if w < 2.5:  # Dashed for modest RR, solid for strong (adjust threshold as needed)\n",
    "        edge_styles.append('dashed')\n",
    "        edge_colors.append('gray')\n",
    "    else:\n",
    "        edge_styles.append('solid')\n",
    "        edge_colors.append('black')\n",
    "\n",
    "# Generate layout without fixed nodes\n",
    "pos = nx.spring_layout(G, k=2.0, scale=10, seed=42)\n",
    "\n",
    "# Dynamically offset each label above the node\n",
    "import math\n",
    "node_size_map = {node: size for node, size in zip(G.nodes(), node_sizes)}\n",
    "offset_scale = 0.02  # Tune as needed for your plot's visual scale\n",
    "label_pos = {\n",
    "    node: (x, y + math.sqrt(node_size_map[node]) * offset_scale)\n",
    "    for node, (x, y) in pos.items()\n",
    "}\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 14))\n",
    "# Draw edges individually by style for dashed/solid with correct width and color\n",
    "for (u, v), style, width, color in zip(G.edges, edge_styles, edge_widths, edge_colors):\n",
    "    nx.draw_networkx_edges(\n",
    "        G, pos,\n",
    "        edgelist=[(u, v)],\n",
    "        style=style,\n",
    "        width=width,\n",
    "        edge_color=color,\n",
    "        alpha=0.5,  # Try 0.05 to 0.25 for dense graphs\n",
    "    )\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='white', edgecolors='black', linewidths=2)\n",
    "nx.draw_networkx_labels(G, label_pos)\n",
    "\n",
    "# Choose prevalence values to illustrate (e.g., 50%, 25%, 10%)\n",
    "legend_prevalence = [0.5, 0.25, 0.10]\n",
    "legend_sizes = [n * 2000 for n in legend_prevalence]\n",
    "\n",
    "# Coordinates where to plot the legend (tune for your plot's scale)\n",
    "base_x = 0.02  # fraction of the figure\n",
    "base_y = 0.02\n",
    "dy = 0.07\n",
    "\n",
    "for i, (p, s) in enumerate(zip(legend_prevalence, legend_sizes)):\n",
    "    plt.scatter([], [], s=s, c='white', edgecolors='black', linewidths=2, label=f\"{int(p*100)}%\")\n",
    "# Place the legend at lower left\n",
    "plt.legend(\n",
    "    scatterpoints=1,\n",
    "    frameon=False,\n",
    "    labelspacing=1.5,\n",
    "    loc='lower left',     # ensures legend is at the bottom left of the graph\n",
    "    title=\"Prevalence\",\n",
    "    fontsize=12,\n",
    "    title_fontsize=13\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77f213a-2dd0-4ec6-a86e-6d88e1bfb949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import fisher_exact\n",
    "import math\n",
    "\n",
    "def plot_one_lca_subgroup(\n",
    "    df, class_id, node_color, comorbidity_cols,\n",
    "    node_size_scale=2000, edge_weight_scale=60, offset_scale=0.055,\n",
    "    legend_prevalence=(0.5, 0.25, 0.1)\n",
    "):\n",
    "    # Subset for LCA class\n",
    "    lca_sub = df[df['latent_class'] == class_id]\n",
    "    N = len(lca_sub)\n",
    "    prevalence = {d: lca_sub[d].sum() / N for d in comorbidity_cols}\n",
    "\n",
    "    # Build network\n",
    "    G = nx.Graph()\n",
    "    for d in comorbidity_cols:\n",
    "        G.add_node(d, prevalence=prevalence[d])\n",
    "    for a, b in combinations(comorbidity_cols, 2):\n",
    "        col_a, col_b = lca_sub[a], lca_sub[b]\n",
    "        n11 = ((col_a == 1) & (col_b == 1)).sum()\n",
    "        n10 = ((col_a == 1) & (col_b == 0)).sum()\n",
    "        n01 = ((col_a == 0) & (col_b == 1)).sum()\n",
    "        n00 = ((col_a == 0) & (col_b == 0)).sum()\n",
    "        table = [[n11, n10], [n01, n00]]\n",
    "        _, pval = fisher_exact(table, alternative='greater')\n",
    "        if n11 > 0 and pval < 0.05:\n",
    "            G.add_edge(a, b, weight=n11/N)\n",
    "\n",
    "    # --- Node and edge visual parameters ---\n",
    "    node_sizes = [prevalence[n] * node_size_scale for n in G.nodes]\n",
    "    edge_weights = [G[u][v]['weight'] * edge_weight_scale for u, v in G.edges]\n",
    "    plt.figure(figsize=(14, 14))\n",
    "    pos = nx.spring_layout(G, k=1, scale=10, iterations=250, seed=42)\n",
    "\n",
    "    # --- Edges: thicker and more visible ---\n",
    "    nx.draw_networkx_edges(G, pos, width=edge_weights, edge_color='gray', alpha=0.6)\n",
    "\n",
    "    # --- Nodes ---\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos, node_size=node_sizes, node_color=node_color, edgecolors='black', linewidths=2, alpha=1\n",
    "    )\n",
    "\n",
    "    # --- Labels with larger offset ---\n",
    "    # Radially offset labels:\n",
    "    center_x, center_y = np.mean([x for x, y in pos.values()]), np.mean([y for x, y in pos.values()])\n",
    "    node_size_map = {node: size for node, size in zip(G.nodes(), node_sizes)}\n",
    "    offset = 0.048\n",
    "    label_pos = {}\n",
    "    for node, (x, y) in pos.items():\n",
    "        dx, dy = x - center_x, y - center_y\n",
    "        r = math.sqrt(node_size_map[node])\n",
    "        dist = np.linalg.norm([dx, dy]) or 1\n",
    "        label_pos[node] = (x + dx/dist*r*offset, y + dy/dist*r*offset)\n",
    "    nx.draw_networkx_labels(G, label_pos, font_size=18)\n",
    "\n",
    "    # --- Node size legend ---\n",
    "    legend_sizes = [n * node_size_scale for n in legend_prevalence]\n",
    "    for p, s in zip(legend_prevalence, legend_sizes):\n",
    "        plt.scatter([], [], s=s, c=node_color, edgecolors='black', linewidths=2, label=f\"{int(p*100)}%\")\n",
    "    plt.legend(\n",
    "        scatterpoints=1,\n",
    "        frameon=False,\n",
    "        labelspacing=1.4,\n",
    "        loc='lower left',\n",
    "        title=\"Prevalence\",\n",
    "        fontsize=14,\n",
    "        title_fontsize=15\n",
    "    )\n",
    "    plt.margins(0.18)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Subgroup {class_id}\", fontsize=28)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example use for your subgroups (using colors like the paperâ€™s Figure 5)\n",
    "subgroup_colors = {\n",
    "    1: \"white\",\n",
    "    3: \"limegreen\",\n",
    "    4: \"blue\",\n",
    "    6: \"magenta\"\n",
    "}\n",
    "for class_id, node_color in subgroup_colors.items():\n",
    "    plot_one_lca_subgroup(lca_cohort, class_id, node_color, comorbidity_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d94273-b910-4de0-8c1f-a6232ca113fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
